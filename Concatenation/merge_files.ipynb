{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from os.path import join as PJOIN\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration parameters to change - \n",
    "DATA_DIR : Directory where outputs X,Y, Z of PrepareTrainingData notebook is present\n",
    "DATA_FILES : Output file names from PrepareTrainingData notebook\n",
    "OUTPUT_FILE : Name of the merged final output file \n",
    "Two sheets will be generated\n",
    "1. Z_<OUTPUT_FILE>.csv - This will contain the file name and the comment name\n",
    "2. <OUTPUT_FILE>.csv - This will contain the 20 features + the calculated comment quality score or label for the comments \n",
    "                       in the same order as present in Z_<OUTPUT_FILE>.csv\n",
    "\"\"\"\n",
    "DATA_DIR = \"DATA/GENERATED/TRAIN/\"\n",
    "commentTypeClassification = False\n",
    "# DATA_FILES = [\"train_libpng_int.csv\",\"train_dealii_int.csv\",\"train_server_int.csv\",\n",
    "#              \"train_curl_Deepesh_commentType.csv\", \"train_curl_Saket_commentType.csv\", \n",
    "#               \"train_curl_Saloni_commentType.csv\", \"train_curl_Yash_commentType.csv\",\n",
    "#              \"train_server_Saket_commentType.csv\", \"train_server_Shubhanan_commentType.csv\",\n",
    "#              \"train_server_Yash_commentType.csv\"]\n",
    "\n",
    "# DATA_FILES = [\"train_dealii_Srinidhi_int.csv\", \"train_libpng_Someone_int.csv\", \"train_server_Someone_int.csv\",\n",
    "#              \"train_curl_Deepesh_commentType.csv\", \"train_curl_Saket_commentType.csv\", \n",
    "#               \"train_curl_Saloni_commentType.csv\", \"train_curl_Yash_commentType.csv\",\n",
    "#              \"train_server_Saket_commentType.csv\", \"train_server_Shubhanan_commentType.csv\",\n",
    "#              \"train_server_Yash_commentType.csv\"]\n",
    "\n",
    "# DATA_FILES = ['train_curl_Deepesh_cal.csv', 'train_curl_Saket_cal.csv', 'train_curl_Saloni_cal.csv',\n",
    "#              'train_curl_Yash_cal.csv', 'train_PLplot_Shubhanan_cal.csv', 'train_PLplot_Saloni_cal.csv',\n",
    "#              'train_server_Saket_cal.csv','train_server_Yash_cal.csv','train_server_Shubhanan_cal.csv',\n",
    "#              'train_dealii_Srinidhi_cal.csv','train_server_3folders_cal.csv','train_libpng-code_allmarked_cal.csv']\n",
    "DATA_FILES = ['train_libpng_billgates_cal.csv']\n",
    "OUTPUT_FILE = \"TEST_SEPARATE\"\n",
    "\n",
    "HEADERS = [\"count of comment tokens\", \"software development count\", \" application specific entities count\", \" descriptive\", \"operational / conditional\",\n",
    "          \"non DT IN words\", \"coherence inconsistent\", \"coherence redundant\", \"scope score\",\n",
    "          \"application specific\", \"developer details\", \"junk/copyright\",'dataset description','working summary','working summary - design','exceptions','build instructions','project management','construct names in comment','comment placements','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes all data files, and concatenates their data to get all_x, all_y and all_z\n",
    "\"\"\"\n",
    "SHAPES = set()\n",
    "def get_all_training_data():\n",
    "    all_files = []\n",
    "    if DATA_FILES[0] == 'all':\n",
    "        for file in os.listdir(DATA_DIR):\n",
    "            if file[:2] == 'X_':\n",
    "                all_files.append(file[2:])\n",
    "    else:\n",
    "        all_files = DATA_FILES\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    all_z = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        train_x = pd.read_csv(PJOIN(DATA_DIR,\"X_\"+file),header=None)\n",
    "        all_x.append(np.array(train_x))\n",
    "        train_y = pd.read_csv(PJOIN(DATA_DIR,\"Y_\"+file),header=None)\n",
    "        all_y.append(train_y)\n",
    "        train_z = pd.read_csv(PJOIN(DATA_DIR,\"Z_\"+file),header=None,delimiter='\\t')\n",
    "        print(train_z[[1,0]])\n",
    "        SHAPES.add(train_z.shape)\n",
    "        all_z.append(train_z[[1,0]])\n",
    "    \n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "    all_z = np.concatenate(all_z)\n",
    "    print(all_x.shape,all_y.shape)\n",
    "    all_y = all_y.reshape(all_y.shape[0])    \n",
    "    return all_x, all_y, all_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes the label data (Y), and returns it as np.array\n",
    "\"\"\"\n",
    "def process_y_commentType(y):\n",
    "    res = []\n",
    "    for el in y:\n",
    "        temp = el.strip('][').split(',')\n",
    "        temp = [int(a) for a in temp]\n",
    "        res.append(temp)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     1  \\\n",
      "0    Define the following to use this test against ...   \n",
      "1                 because png.h did *not* include this   \n",
      "2    1.6.1 added support for the configure test har...   \n",
      "3         READ_PNG and WRITE_PNG were not defined, so:   \n",
      "4                                      SEQUENTIAL_READ   \n",
      "..                                                 ...   \n",
      "213                                      Not an option   \n",
      "214                    abort on user or internal error   \n",
      "215  Here on any return, including failures, except...   \n",
      "216                           Release allocated memory   \n",
      "217                                          !READ_PNG   \n",
      "\n",
      "                                                 0  \n",
      "0    repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "1    repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "2    repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "3    repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "4    repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "..                                             ...  \n",
      "213  repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "214  repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "215  repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "216  repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "217  repos/libpng-code/contrib/libtests/pngimage.c  \n",
      "\n",
      "[218 rows x 2 columns]\n",
      "(218, 20) (218, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, train_z = get_all_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing the merged Z output in file Z_OUTPUT_FILE\n",
    "with open(DATA_DIR+\"Z_\"+OUTPUT_FILE+\".csv\", 'w') as f:\n",
    "    writer = csv.writer(f, delimiter = '\\t')\n",
    "    header = ['F2','FILES']\n",
    "    writer.writerow(header)\n",
    "    for el in train_z:\n",
    "        writer.writerow(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing the merged X and Y output in file OUTPUT_FILE\n",
    "with open(DATA_DIR+OUTPUT_FILE+\".csv\", 'w') as f:\n",
    "    writer = csv.writer(f, delimiter = '\\t')\n",
    "    writer.writerow(HEADERS)\n",
    "    for j,l in enumerate(train_x):\n",
    "        writer.writerow(np.append(l,train_y[j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
